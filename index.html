<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/>
    <meta name="description" content=""/>
    <meta name="author" content=""/>
    <title>Michal Stefanik</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico"/>
    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet"
          type="text/css"/>
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css"/>
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet"/>
</head>
<body id="page-top">
<!-- Navigation-->
<nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Michal Štefánik</span>
        <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2"
                                             src="assets/img/profile.jpg" alt="..."/></span>
    </a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
            aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span
            class="navbar-toggler-icon"></span></button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav">
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#talks">Talks</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#other">Other</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#afk">Disconnected</a></li>
            <!--                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li>-->
        </ul>
    </div>
</nav>
<!-- Page Content-->
<div class="container-fluid p-0">
    <!-- About-->
    <section class="resume-section" id="about">
        <div class="resume-section-content">
            <h1 class="mb-0">
                <!--                        <span class="text-primary">Michal Štefánik</span>-->
                Michal Štefánik
            </h1>
            <div class="subheading mb-5">
                Researcher in Natural Language Processing
                <p><a href="mailto:stefanik.m@mail.muni.cz"> stefanik.m@mail.muni.cz</a></p>
            </div>
            <div class="social-icons">
                <a class="social-icon" href="https://scholar.google.com/citations?user=9p-110IAAAAJ&hl=en&oi=ao"><img
                        width="48%" height="48%" object-fit="contain" src="assets/img/gscholar-icon.png"/></a>
                <a class="social-icon" href="https://www.linkedin.com/in/stefanikm"><i
                        class="fab fa-linkedin-in"></i></a>
                <a class="social-icon" href="https://github.com/stefanik12"><i class="fab fa-github"></i></a>
                <a class="social-icon" href="https://www.facebook.com/stefanik.mich"><i
                        class="fab fa-facebook-f"></i></a>
                <p></p>
                <p></p>
            </div>
            <p class="lead mb-5"></p>
            <p class="lead mb-6">Welcome to my webpage! I am a third-year PhD candidate in the <a
                    href="https://www.fi.muni.cz/about/">Faculty of Informatics</a> of
                <a href=https://www.muni.cz/en>Masaryk University</a>
                and an NLP team lead in <a href="https://www.gaussalgo.com/en/">Gauss Algorithmic</a>.
            </p>
            <p class="lead mb-6">
                My <strong>research interests</strong> are in everything around <strong>robustness of the language
                models</strong>.
                Among others, this closely relates to <strong>domain adaptation</strong>,
                <strong>generalization</strong>, <strong>quality estimation</strong> or robust
                <strong>low-resource</strong> applications.

            </p>
            <p class="lead mb-6">
                Apart from my own research, I am a founder of student <a href="#supervisor">Transformers Club</a>, whose
                alumni were awarded with
                two Dean's awards, a SVOC prize or a 1st place in NAACL DADC workshop track.
            </p>
            <p class="lead mb-6">
                Over the last five years, I've also contributed and led the delivery of the <strong>industrial
                applications</strong> of the most recent NLP research
                in multilingual <a href="https://www.gaussalgo.com/en/case-studies/lectura-and-seo-text-optimalization">language
                generation</a>, or
                <a href="https://www.gaussalgo.com/en/cyber-security/revealing-sensitive-documents-with-ner-practical-case-study">entity
                    recognition</a>,
                all the way from the research ideas to the scalable, containerized deployments, now daily serving the
                fascinating NLP technologies to end users.
            </p>
        </div>
    </section>
    <hr class="m-0"/>
    <!-- Experience-->
    <section class="resume-section" id="publications">
        <div class="resume-section-content">
            <h2 class="mb-5">Publications</h2>
            <p>Here's a selection of recent publications I have conducted or significantly contributed to.
            </p>
            </br>
            <h3 class="mb-2"><span class="text-primary">2022</span></h3>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Think Twice: Measuring the Efficiency of Eliminating Model Biases in Question Answering</h3>
                    <div class="lead mb-3">Under review, <a
                            href="https://openreview.net/pdf?id=Sp7FydWipmaM">available
                        here</a></div>
                    <p>We introduce a framework for finer-grained analysis of discovered model biases and measure the
                        significance of some previously-reported biases while uncovering several new ones.
                        The bias-level metric allows us to assess how well different pre-trained models and
                        state-of-the-art debiasing methods mitigate the identified biases in Question Answering (QA) and
                        compare their results to a resampling baseline.
                        We find cases where bias mitigation hurts OOD performance and,
                        on the contrary, when bias enlargement corresponds to improvements in OOD,
                        suggesting that some biases are shared among QA datasets and motivating future work to refine
                        the analyses of LLMs' robustness.
                    </p>
                </div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Alignment-Based Objectives for Robust Adaptation in Machine Translation</h3>
                    <div class="lead mb-3">Under review, <a
                            href="https://drive.google.com/file/d/1e9bYySB5Cuz953ZpzDN3e0kvOFUi2MOA/view?usp=sharing">available
                        here</a></div>
                    <p>The traditional adaptation by continuous in-domain training weakens the model's ability to
                        generalize to other domains, making the open-ended deployment of these models prone to errors.
                        This work introduces two novel objectives, grounded in a semantic similarity of the generating
                        hypothesis to the reference. We show that (1) grounding of the training signal in semantic
                        similarity can mitigate the catastrophic forgetting of domain adaptation, while (2) in many
                        cases improving the performance on the adapted domain, (3) with negligible additions to compute
                        costs. In the broader sense, our objectives grounded in a soft token-level alignment pioneer the
                        exploration of the middle ground between the efficient but narrow exact-match token-level
                        objectives and expressive but computationally- and resource-intensive sentence-level
                        objectives.</p>
                </div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Methods for Estimating and Improving Robustness of Language Models</h3>
                    <div class="subheading mb-3"><span class="text-primary">Michal Štefánik</span></div>
                    <div class="lead mb-3">In <a href="https://aclanthology.org/2022.naacl-srw.6/">Proceedings of 2022
                        Annual Conference of the NAACL: SRW</a></div>
                    <p>Despite their outstanding performance, large language models (LLMs) suffer notorious flaws
                        related to their preference for simple, surface-level textual relations over full semantic
                        complexity of the problem. This proposal investigates a common denominator of this problem in
                        their weak ability to generalise outside of the training domain. We survey diverse research
                        directions providing estimations of model generalisation ability and find that incorporating
                        some of these measures in the training objectives leads to enhanced distributional robustness of
                        neural models. Based on these findings, we present future research directions towards enhancing
                        the robustness of LLMs.</p>
                    <p><a href="#talks">Conference talk ⬇️</a>️</p>
                </div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Adaptor: Objective-Centric Adaptation Library for Language Models</h3>
                    <div class="subheading mb-3"><span class="text-primary">Michal Štefánik</span>, Vít Novotný, Nikola
                        Groverová, Petr Sojka
                    </div>
                    <div class="lead mb-3">In <a href="https://aclanthology.org/2022.acl-demo.26/">Proceedings of the
                        60th Annual Meeting of the ACL: Demonstrations</a></div>
                    <p>This paper introduces Adaptor library, transposing the traditional model-centric approach
                        composed of pre-training + fine-tuning steps to objective-centric approach, composing the
                        training from applications of selected objectives. We survey research directions that can
                        benefit from enhanced objective-centric experimentation in multitask training, custom objectives
                        development, dynamic training curricula, or domain adaptation and demonstrate the practical
                        applicability of Adaptor in selected unsupervised domain adaptation scenarios.</p>
                    <p><a href="#talks">Introduction talk ⬇️</a>️</p>
                </div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">When FastText Pays Attention: Efficient Estimation of Word Representations using
                        Constrained Positional Weighting</h3>
                    <div class="subheading mb-3">Vít Novotný, <span class="text-primary">Michal Štefánik</span>, Eniafe
                        Festus Ayetiran, Petr Sojka, Radim Řehůřek
                    </div>
                    <div class="lead mb-3">In <a href="https://lib.jucs.org/article/69619/">JUCS: The Journal of
                        Universal Computer Science</a></div>
                    <p>We propose a constrained positional model, which adapts the sparse attention mechanism from
                        neural machine translation to improve the speed of the positional model. Our constrained model
                        outperforms the positional model on language modelling and trains twice as fast.</p>
                </div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Applications of deep language models for reflective writings</h3>
                    <div class="subheading mb-3">Jan Nehyba & <span class="text-primary">Michal Štefánik</span> (equal)
                    </div>
                    <div class="lead mb-3">In <a href="https://rdcu.be/cUWGY">Education and Information Technologies</a>
                    </div>
                    <p>Social sciences expose many cognitively complex, highly qualified, or fuzzy
                        problems, whose resolution relies primarily on expert judgement rather than
                        automated systems. One of such instances that we study in this work is a
                        reflection analysis in the writings of student teachers. We share a hands-on
                        experience on how these challenges can be successfully tackled in data collection
                        for machine learning.</p>
                </div>
            </div>

            <h3 class="mb-2"><span class="text-primary">2021</span></h3>

            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">RegEMT: Regressive Ensemble for Machine Translation Quality Evaluation</h3>
                    <div class="subheading mb-3"><span class="text-primary">Michal Štefánik</span>, Vít Novotný, Petr
                        Sojka
                    </div>
                    <div class="lead mb-3">In <a href="https://aclanthology.org/2021.wmt-1.112/">Proceedings of the
                        Sixth Conference on Machine Translation (WMT)</a></div>
                    <p>This work introduces a simple regressive ensemble for evaluating machine translation quality
                        based on a set of novel and established metrics. We evaluate the ensemble using a correlation to
                        expert-based MQM scores of the WMT 2021 Metrics workshop. In both monolingual and zero-shot
                        cross-lingual settings, we show a significant performance improvement over single metrics. In
                        the cross-lingual settings, we also demonstrate that an ensemble approach is well-applicable to
                        unseen languages. Furthermore, we identify a strong reference-free baseline that consistently
                        outperforms the commonly-used BLEU and METEOR measures and significantly improves our ensemble’s
                        performance.</p>
                </div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">One Size Does Not Fit All: Finding the Optimal Subword Sizes for FastText Models
                        across Languages</h3>
                    <div class="subheading mb-3">Vít Novotný, Eniafe Festus Ayetiran, Dalibor Bačovský, Dávid Lupták,
                        <span class="text-primary">Michal Štefánik</span>, Petr Sojka
                    </div>
                    <div class="lead mb-3">In <a href="https://aclanthology.org/2021.ranlp-1.120/">Proceedings of the
                        International Conference on Recent Advances in NLP (RANLP 2021)</a></div>
                    <p>In our work, we find the optimal subword sizes on the English, German, Czech, Italian, Spanish,
                        French, Hindi, Turkish, and Russian word analogy tasks. We then propose a simple n-gram coverage
                        model and we show that it predicts better-than-default subword sizes on the Spanish, French,
                        Hindi, Turkish, and Russian word analogy tasks. We show that the optimization of fastText’s
                        subword sizes matters and results in a 14% improvement on the Czech word analogy task. We also
                        show that expensive parameter optimization can be replaced by a simple n-gram coverage model
                        that consistently improves the accuracy of fastText models on the word analogy tasks by up to 3%
                        compared to the default subword sizes, and that it is within 1% accuracy of the optimal subword
                        sizes.</p>
                </div>
            </div>

            <h3 class="mb-2"><span class="text-primary">2020</span></h3>


            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Text classification with word embedding regularization and soft similarity
                        measure</h3>
                    <div class="subheading mb-3">Vít Novotný, Eniafe Festus Ayetiran, <span class="text-primary">Michal Štefánik</span>,
                        Petr Sojka
                    </div>
                    <div class="lead mb-3">In <a href="https://arxiv.org/pdf/2003.05019.pdf">ArXiv</a></div>
                    <p>In our work, we investigate the individual and joint effect of the word embedding regularization
                        techniques on the document processing speed and the task performance of the SCM and the WMD on
                        text classification. For evaluation, we use the kNN classifier and six standard datasets:
                        BBCSPORT, TWITTER, OHSUMED, REUTERS-21578, AMAZON, and 20NEWS. We show 39% average kNN test
                        error reduction with regularized word embeddings compared to non-regularized word embeddings. We
                        describe a practical procedure for deriving such regularized embeddings through Cholesky
                        factorization. We also show that the SCM with regularized word embeddings significantly
                        outperforms the WMD on text classification and is over 10,000× faster.</p>
                </div>
            </div>
        </div>
    </section>
    <hr class="m-0"/>
    <!-- Experience-->
    <section class="resume-section" id="experience">
        <div class="resume-section-content">
            <h2 class="mb-5">Experience</h2>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">NLP Scientist - Team Lead</h3>
                    <div class="subheading mb-3">Gauss Algorithmic</div>
                    <div>Guiding the most recent NLP research applications from whiteboards to the users.
                    </div>
                    <br>Creating the ideas that widen the applicability of NLP to novel areas but also coordinating the
                    delivery within the team of three tenure NLP scientists and multiple software developers, operations
                    engineers, business developers and copywriters. </br>
                    <br>See our <a href="https://www.gaussalgo.com/en/blog">blogs</a>, <a
                        href="https://www.gaussalgo.com/en/case-studies/lectura-and-seo-text-optimalization">case
                    studies</a>, <a href="https://demo-hub.gaussalgo.com/">demos</a> or <a
                        href="https://github.com/gaussalgo/adaptor">open-source</a> projects.</br>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">March 2021 - now</span></div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">NLP Scientist</h3>
                    <div class="subheading mb-3">Gauss Algorithmic</div>
                    <div>Creating the prototypes of NLP applications for specific use-cases,
                        in multilingual classification, named entity recognition, or language generation.
                    </div>
                    <br>Responsibilities ranging from communicating the customers' expectations to stable deployments of
                    containerized applications.</br>
                    <br>Implementations using Python & PyTorch, deployments using CI, Docker & Kubernetes in AWS and
                    Google Cloud.</br>
                    <br></br>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">June 2018 - March 2021</span></div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Junior Software Developer</h3>
                    <div class="subheading mb-3">Red Hat Software</div>
                    <div>Enhancing the company search engines with semantic text representations and classification,
                        within the <a href="https://github.com/searchisko/project-classifier-poc">Searchisko</a> & other
                        open-source projects.
                    </div>
                    <br>Application of NLP technologies such as Word2Vec, and FastText. Implementations in Python &
                    Java, deployments in OpenShift.
                    </br>
                    <br></br>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">March 2015 - June 2018</span></div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Stream Processing Developer</h3>
                    <div class="subheading mb-3">CSIRT: Cyber Security Team of Masaryk Univerity</div>
                    <div>Research & development of intrusion detection methods in scalable, streaming paradigms.</div>
                    <br>Implementations of unsupervised and semi-supervised methods, Apache Spark & Python.
                    Open-sourced in <a href="https://github.com/CSIRT-MU/Stream4Flow">Stream4Flow</a> project.
                    </br>

                </div>
                <div class="flex-shrink-0"><span class="text-primary">March 2016 - September 2017</span></div>
            </div>
        </div>
    </section>
    <hr class="m-0"/>
    <!-- Talks -->
    <section class="resume-section" id="talks">
        <div class="resume-section-content">
            <h2 class="mb-5">Talks</h2>

            <h3 class="mb-0">Learning to Learn: Training Language Models to Understand Tasks from Few Examples</h3>
            <div class="subheading mb-3"><span class="text-primary">Community talk: Machine Learning MeetUp Brno, October 2022 (Offline)</span>
                <br></br>
                <p>Informal presentation of our methodology and trained models for Few-shot in Czech and other Non-English languages.<br>
                    <a href="https://www.facebook.com/events/6396221753725366/?active_tab=about">Abstract</a> &
                    <a href="https://drive.google.com/file/d/1xO7V0AmE57eH4FAoH517XZPQ0_DtOoby/view?usp=sharing">Presentation with links</a> &
                    <a href="https://huggingface.co/gaussalgo/mt5-large-priming-QA_en-cs">HuggingFace models</a>.</p>
                <img alt="MLMU Cover Photo"
                     src="https://secure.meetupstatic.com/photos/event/3/2/6/9/highres_507252905.jpeg" loading="eager"
                     class="rounded-full object-cover" style="width: 560px; height: 315px;">
                <br></br>
            </div>

            <h3 class="mb-0">Mitigating Biases of QA Models by Simple Resampling Methods</h3>
            <div class="subheading mb-3"><span class="text-primary">2022 Annual Conference of the NAACL: DADC Workshop, July 2022</span>
                <br></br>
                <p>Results announcement and recording of Supersamplers' team presentation, live on NAACL 2022
                    DADC workshop in Seattle.</p>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/lMochKhgdZg"
                        title="YouTube video player" frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe>
                <br></br>
            </div>


            <h3 class="mb-0">Methods for Estimating and Improving Robustness of Language Models</h3>
            <div class="subheading mb-3"><span
                    class="text-primary">2022 Annual Conference of the NAACL: SRW, July 2022</span>
                <br></br>
                <p>A 5min talk given with the thesis proposal presented on NAACL 2022 SRW in Seattle.</p>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/dTltkOXeeyk"
                        title="YouTube video player" frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe>
                <br></br>
            </div>

            <h3 class="mb-0">Adaptor: Objective-Centric Adaptation Library for Language Models</h3>
            <div class="subheading mb-3"><span class="text-primary">60th Annual Meeting of the ACL, May 2022</span>

                <br></br>
                <p>Blitz 2min introduction video of Adaptor library presented on ACL 2022 in Dublin.</p>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/soP6gIVr46E"
                        title="YouTube video player" frameborder="0"
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe>
                <br></br>
            </div>
        </div>

    </section>
    <hr class="m-0"/>

    <!-- Other -->
    <section class="resume-section" id="other">
        <div class="resume-section-content">
            <h2 class="mb-5">Other Activities</h2>

            <div class="d-flex flex-column flex-md-row justify-content-between">

                <div class="flex-grow-1">
                    <h3 class="mb-0">Coordinator</h3>
                    <div class="subheading mb-3">Intelligent Back Office: Grant Project</div>
                    <p>Coordination of the research in a team of five researchers within the larger, multi-organization
                        <a href="https://www.muni.cz/en/research/projects/64989">grant project</a> focused on improving
                        document processing quality for specialised domain(s).</p>
                    <div>Our research objectives are (a) to enhance the quality of domain-specific OCR text extraction
                        utilising semi-supervised language modelling and (b) to utilise relative positional information
                        of the document segments for a more accurate extraction of the named entities.
                    </div>
                    <br></br>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">January 2022 - now</span></div>

            </div>


            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Lecturer</h3>
                    <div class="subheading mb-3">Course: Introduction to Information Retrieval</div>
                    <p>Over the three years, I have given practicals for 100+ master's students on the essentials of
                        text representations,
                        indexing methods or machine learning approaches to a full-text search.</p>
                    <div>I have also initiated the redesign of the course to a semestral competition based on an
                        easy-to-use
                        <a href="https://github.com/MIR-MU/pv211-utils">evaluation framework</a>.
                        Given the results of semestral student surveys, the competition model enhanced the students'
                        engagement and interest in the NLP topics. The competition results also allow us to reach out to
                        the best students with an offer for further research cooperation.
                    </div>

                    <br></br>
                </div>

                <div class="flex-shrink-0"><span class="text-primary">Springs 2019 - 2022</span></div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0" id="supervisor">Supervisor</h3>
                    <div class="subheading mb-3">Transformers Club & others</div>
                    <p>I have supervised numerous bachelor's and master's theses on topics closely related
                        to the robustness of language models. For the more ambitious students, I organize the weekly
                        meetings of <strong>Transformers Club</strong>, a shared platform for pursuing creative
                        ideas, peer reviewing and organizing teams to address more complex problems.</p>
                    <p>The theses that emerged from the Club and/or I have supervised:</p>
                    <ul>
                        <li>Lukas Mikula: <a href="https://is.muni.cz/th/adh58/?lang=en">Think Twice Before You Answer:
                            Mitigating Biases of Question Answering Models</a> (2022);
                            🥇 1st place in <a href="https://dadcworkshop.github.io/">NAACL DADC</a> shared task Track 2
                            &
                            🏆 a <a href="https://www.fi.muni.cz/about/awards/awards.html.en">Dean's award</a>.
                        </li>
                        <li>Marek Petrovič: <a href="https://is.muni.cz/th/htvm4/?lang=en">One Bit at a Time: Impact of
                            Quantisation on Neural Machine Translation</a> (2022);
                            🏆 a <a href="https://www.fi.muni.cz/about/awards/awards.html.en">Dean's award</a> &
                            🥉 3rd place in <a href="http://math.sk/svoc2022/#vysledky">SVOC</a> competition.
                        </li>
                        <li>Matej Meško: <a href="https://is.muni.cz/th/utq47/?lang=en">Evaluation of a Supervised
                            Approach to Information Retrieval</a> (2022)
                        </li>
                        <li>Martin Geletka: <a href="https://is.muni.cz/th/if8vh/?lang=en">Speeding up inference time of
                            neural machine translation</a> (2021);
                            🎖 Nomination for a Dean's award.
                        </li>
                        <li>Petr Mička: <a href="https://is.muni.cz/th/z52vo/?lang=en">Utilisation of language
                            representations for Information Retrieval</a> (2021)
                        </li>

                    </ul>
                    <br></br>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">Autumn 2020 - now</span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Reviewer</h3>
                    <div class="subheading mb-3">*ACL Conferences & others</div>
                    <p>I give back to the community by volunteering for reviewing, proofreading and providing feedback
                        to other researchers whenever it can help. Feel free to get in touch if you're interested!
                        <br></br>
                        <br></br>
                </div>

            </div>

        </div>
    </section>

    <!-- Other -->
    <section class="resume-section" id="afk">
        <div class="resume-section-content">
            <h2 class="mb-5">Away From Keyboard</h2>
            <br></br>
            <br>Reading the most recent pre-prints is fun, but the world also has a lot of other great stuff to see and
            do.</br>
            <br>Whenever possible, I love spending time moving with unlimited open space ☁ ⬆ above my head, best done on
            a
            bike 🚲 or skis ⛷, with far mountain views ⛰☀️ and a taste of a cold brew ☕ .</br>
        </div>


    </section>
</div>
</section>
<hr class="m-0"/>
</div>
<!-- Bootstrap core JS-->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
<!-- Core theme JS-->
<script src="js/scripts.js"></script>
</body>
</html>

